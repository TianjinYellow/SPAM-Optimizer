[32m2025-01-02 04:42:52.925[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m217[0m - [1mUsing dist with rank 0 (only rank 0 will log)[0m
[32m2025-01-02 04:42:52.925[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m218[0m - [1m****************************************[0m
[32m2025-01-02 04:42:52.925[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m219[0m - [1mStarting training with the arguments[0m
[32m2025-01-02 04:42:52.925[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mmodel_config                   configs/llama_1b.json[0m
model_config                   configs/llama_1b.json
[32m2025-01-02 04:42:52.926[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1muse_hf_model                   False[0m
use_hf_model                   False
[32m2025-01-02 04:42:52.926[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mcontinue_from                  None[0m
continue_from                  None
[32m2025-01-02 04:42:52.926[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mbatch_size                     64[0m
batch_size                     64
[32m2025-01-02 04:42:52.926[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mgradient_accumulation          8[0m
gradient_accumulation          8
[32m2025-01-02 04:42:52.926[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mtotal_batch_size               512[0m
total_batch_size               512
[32m2025-01-02 04:42:52.926[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mmax_length                     256[0m
max_length                     256
[32m2025-01-02 04:42:52.926[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1moptimizer                      SPAM[0m
optimizer                      SPAM
[32m2025-01-02 04:42:52.926[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mlr                             0.002[0m
lr                             0.002
[32m2025-01-02 04:42:52.927[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mscheduler                      cosine[0m
scheduler                      cosine
[32m2025-01-02 04:42:52.927[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mmin_lr_ratio                   0.1[0m
min_lr_ratio                   0.1
[32m2025-01-02 04:42:52.927[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mactivation_checkpointing       False[0m
activation_checkpointing       False
[32m2025-01-02 04:42:52.927[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mweight_decay                   0.0[0m
weight_decay                   0.0
[32m2025-01-02 04:42:52.927[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mwarmup_steps                   1000[0m
warmup_steps                   1000
[32m2025-01-02 04:42:52.927[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1meval_every                     1000[0m
eval_every                     1000
[32m2025-01-02 04:42:52.927[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mnum_training_steps             20000[0m
num_training_steps             20000
[32m2025-01-02 04:42:52.927[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mmax_train_tokens               None[0m
max_train_tokens               None
[32m2025-01-02 04:42:52.927[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1msave_every                     2000[0m
save_every                     2000
[32m2025-01-02 04:42:52.927[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1msave_dir                       /scratch-shared/HTJ2/checkpoints/new0_9209505[0m
save_dir                       /scratch-shared/HTJ2/checkpoints/new0_9209505
[32m2025-01-02 04:42:52.928[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mtags                           None[0m
tags                           None
[32m2025-01-02 04:42:52.928[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mdtype                          bfloat16[0m
dtype                          bfloat16
[32m2025-01-02 04:42:52.928[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mworkers                        8[0m
workers                        8
[32m2025-01-02 04:42:52.928[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mseed                           0[0m
seed                           0
[32m2025-01-02 04:42:52.928[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mname                           test[0m
name                           test
[32m2025-01-02 04:42:52.928[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mmodel_type                     llama[0m
model_type                     llama
[32m2025-01-02 04:42:52.928[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mgrad_clipping                  0.0[0m
grad_clipping                  0.0
[32m2025-01-02 04:42:52.928[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mbeta1                          0.0[0m
beta1                          0.0
[32m2025-01-02 04:42:52.928[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mrank                           0.3225388601036269[0m
rank                           0.3225388601036269
[32m2025-01-02 04:42:52.928[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mupdate_proj_gap                500[0m
update_proj_gap                500
[32m2025-01-02 04:42:52.928[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mgalore_scale                   1.0[0m
galore_scale                   1.0
[32m2025-01-02 04:42:52.929[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mupdating_mask_method           interaction[0m
updating_mask_method           interaction
[32m2025-01-02 04:42:52.929[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1minit_mask                      random[0m
init_mask                      random
[32m2025-01-02 04:42:52.929[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1msingle_gpu                     False[0m
single_gpu                     False
[32m2025-01-02 04:42:52.929[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mmask_grad                      False[0m
mask_grad                      False
[32m2025-01-02 04:42:52.929[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mspike_clip                     True[0m
spike_clip                     True
[32m2025-01-02 04:42:52.929[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1msampling                       False[0m
sampling                       False
[32m2025-01-02 04:42:52.929[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mload_local                     False[0m
load_local                     False
[32m2025-01-02 04:42:52.929[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mm_replace                      False[0m
m_replace                      False
[32m2025-01-02 04:42:52.929[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mwarmup_epoch                   150[0m
warmup_epoch                   150
[32m2025-01-02 04:42:52.930[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mthreshold                      5000.0[0m
threshold                      5000.0
[32m2025-01-02 04:42:52.930[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m221[0m - [1mgrad_accu_steps                20.0[0m
grad_accu_steps                20.0
[32m2025-01-02 04:42:52.930[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m223[0m - [1m****************************************[0m
Resolving data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:02<00:00, 366.32it/s]
Resolving data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:00<00:00, 473744.46it/s]
[32m2025-01-02 04:43:00.795[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m236[0m - [1mShuffling data with seed 42[0m
/home/huangti/miniconda3/envs/spam/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
Update steps:   0%|                                   | 0/20000 [00:00<?, ?it/s][32m2025-01-02 04:43:15.658[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m356[0m - [1m
LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(32000, 2048, padding_idx=31999)
    (layers): ModuleList(
      (0-23): 24 x LlamaDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)
          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)
          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)
          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=2048, out_features=5461, bias=False)
          (down_proj): Linear(in_features=5461, out_features=2048, bias=False)
          (up_proj): Linear(in_features=2048, out_features=5461, bias=False)
          (act_fn): SiLUActivation()
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)
)
[0m
[32m2025-01-02 04:43:15.658[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m357[0m - [1mTotal params: 1339.08M[0m
[32m2025-01-02 04:43:15.659[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m358[0m - [1mTrainable params: 1339.08M[0m
[32m2025-01-02 04:43:15.659[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m361[0m - [1mSaving model to /scratch-shared/HTJ2/checkpoints/new0_9209505 every 2000 update steps[0m
/gpfs/home2/huangti/SPAM_v2/galore_torch/SPAM.py:68: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
density 0.3225388042026958
/home/huangti/miniconda3/envs/spam/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/conda/conda-bld/pytorch_1728945379270/work/aten/src/ATen/native/cudnn/MHA.cpp:674.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass

loss at 8 1.34375
Update steps:   0%|                        | 8/20000 [01:36<50:11:48,  9.04s/it]
